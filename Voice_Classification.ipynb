{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voice Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUB+pBBGKbo2OaV/leu6df",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takanto/CNN_Voice_Detection/blob/main/Voice_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN Voice Classification**"
      ],
      "metadata": {
        "id": "zxE2DwFdczeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook contains the code for training the voice classification model using CNN and storing the model for later use in mobile app. The motive behind this model is to prevent many phone scam, creating devastating financial damages especially to elderlies who cannot distinguish the voices of their children and the scammers. By training this model specifically to distinguish the voices of their children and scammers, elderies do not have to rely on their ability but AI to identify whether a call is by scammers or not. "
      ],
      "metadata": {
        "id": "BX1lLn9Ac9PB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training, please not forget to run with TPU to speed up the training process, and divide training into multiple times if necessary. (When dividing the training, it is recommended that you keep track of epochs by adding number of epochs to the names of the model you save) "
      ],
      "metadata": {
        "id": "6Qvjsbk7DflJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code**"
      ],
      "metadata": {
        "id": "XB9c37n0d_eA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preparation**"
      ],
      "metadata": {
        "id": "7KA0RAuheCnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code before any operation."
      ],
      "metadata": {
        "id": "BT89bCFyeIp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Importing important libraries."
      ],
      "metadata": {
        "id": "DQYZLzWheMRK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K-8RSn4CY91N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2DTranspose, MaxPooling2D, Dropout, BatchNormalization, Reshape, LeakyReLU, Conv2D\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 as PretrainedModel, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "B6VNDmM6ZBxu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Setting up TPU environment."
      ],
      "metadata": {
        "id": "kwXAytLDeR8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"\")\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"all devices:\", tf.config.list_logical_devices(\"TPU\"))"
      ],
      "metadata": {
        "id": "6d6Aa691ZFRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "N6LO-CCfZLmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Preprocessing training data. Please import your training file. Training file needs to contain 100000+ .wav files of voices of family members and non-family members. Voice of non-family members will be provided in the github page in later version. "
      ],
      "metadata": {
        "id": "TeuaS1syeWA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from opensoundscape.audio import Audio\n",
        "from opensoundscape.spectrogram import Spectrogram\n",
        "from pathlib import Path\n",
        "\n",
        "folder = 'name of the training file'\n",
        "\n",
        "if not os.path.exists(\"spectrogram\"):\n",
        "  os.makedirs(\"spectrogram\")\n",
        "\n",
        "for audio_filename in os.listdir(folder):\n",
        "  # Settings\n",
        "  image_shape = (224, 224) \n",
        "  image_save_path = Path('spectrogram/'+audio_filename+'.png')\n",
        "\n",
        "  audio = Audio.from_file(audio_filename)\n",
        "\n",
        "  spectrogram = Spectrogram.from_audio(audio)\n",
        "\n",
        "  image = spectrogram.to_image(shape=image_shape,invert=True)\n",
        "\n",
        "  image.save(image_save_path)"
      ],
      "metadata": {
        "id": "BbqBiu49ZOVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os, numpy as np\n",
        "\n",
        "folder = 'spectrogram'\n",
        "\n",
        "read = lambda imname: np.asarray(Image.open(imname).convert(\"L\"))\n",
        "\n",
        "ims = [read(os.path.join(folder, filename)) for filename in os.listdir(folder)]\n",
        "im_array = np.array(ims, dtype='uint8')\n",
        "im_array = (im_array / 255.0)*2 - 1"
      ],
      "metadata": {
        "id": "SlyFdXQYapnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_array_scammers = np.load('scammer_file') # scammer file will be added"
      ],
      "metadata": {
        "id": "gDFu8gpEcnWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **First Time Running**"
      ],
      "metadata": {
        "id": "U10bcnLr9-_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below code when you're first time traning the model"
      ],
      "metadata": {
        "id": "1KEORzer-H17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Define detector"
      ],
      "metadata": {
        "id": "pre7EGiC-fqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_detector(image_size):\n",
        "  i = Input(shape=image_size)\n",
        "  x = Conv2D(64,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(i)\n",
        "  x = Conv2D(128,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2D(128,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2D(256,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = Model(i,x)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-ODrjXYh-F82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Check the archtecture of the model"
      ],
      "metadata": {
        "id": "2HUb0S7_-8Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector_check = build_detector((214,214,1))\n",
        "detector_check.summary()"
      ],
      "metadata": {
        "id": "3SCp6fHK-lHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Set up important variables"
      ],
      "metadata": {
        "id": "mCnQCrioC2Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 10000\n",
        "\n",
        "ones = np.ones(batch_size)\n",
        "zeros = np.zeros(batch_size)\n",
        "\n",
        "d_losses = []\n",
        "d_accs = []"
      ],
      "metadata": {
        "id": "qBDRFQojBHTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Actual Training"
      ],
      "metadata": {
        "id": "B0Teb8T8C6rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  detector = build_detector((214,214,1))\n",
        "  detector.compile(optimizer = Adam(0.0002, 0.5),\n",
        "                      loss = \"binary_crossentropy\",\n",
        "                      metrics = [\"accuracy\"])\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    idx = np.random.randint(0, im_array.shape[0], batch_size)\n",
        "    real_imgs = im_array[idx]\n",
        "\n",
        "    idx = np.random.randint(0, im_array_scammers.shape[0], batch_size)\n",
        "    fake_imgs = im_array_scammers[idx]\n",
        "\n",
        "    d_loss_real, d_acc_real = detector.train_on_batch(real_imgs, ones)\n",
        "    d_loss_fake, d_acc_fake = detector.train_on_batch(fake_imgs, zeros)\n",
        "    d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "    d_acc = (d_acc_real + d_acc_fake) / 2\n",
        "\n",
        "    d_losses.append(d_loss)\n",
        "    d_accs.append(d_acc)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"epoch: {epoch+1} / {epochs}, d_loss: {d_loss:.2f}, d_acc: {d_acc:.2f}\")"
      ],
      "metadata": {
        "id": "d_wG1EZr-7Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Save the model and weights (Make sure to download them on your hard drive)"
      ],
      "metadata": {
        "id": "5MSy1futC9RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector.save(\"detector_model.h5\")\n",
        "detector_weights = detector.get_weights()\n",
        "np.save('detector_weights', detector_weights)"
      ],
      "metadata": {
        "id": "idE9jhZOCAeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Run below if you want the diagram for loss and accuracy of the model over time"
      ],
      "metadata": {
        "id": "8DEnGiuTDAJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_losses, label = \"d_losses\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "I9riaWISCoc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_accs, label = \"d_accs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "yiqBQ85cCtzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Additional Training of your model**"
      ],
      "metadata": {
        "id": "k0YrF3WODLqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you already have your model and weights trained and want to train your model even more, below is the code you need to run."
      ],
      "metadata": {
        "id": "oIrPY9gGDR5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　Loading in your model and weights. (when you set different name, please reflect changes here too.)"
      ],
      "metadata": {
        "id": "hr9mdUi5DVuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector_loaded = tf.keras.load_model(\"detector_model.h5\")\n",
        "detector_weights = np.load(\"detector_weights\", allow_pickle = True)\n",
        "\n",
        "detector_loaded.set_weights(detector_weights)"
      ],
      "metadata": {
        "id": "n4Di0to2DWLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Training"
      ],
      "metadata": {
        "id": "1L6BmtLPEk-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 10000\n",
        "\n",
        "ones = np.ones(batch_size)\n",
        "zeros = np.zeros(batch_size)\n",
        "\n",
        "d_losses = []\n",
        "d_accs = []"
      ],
      "metadata": {
        "id": "eRp_ELOOEAkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  detector = build_detector((214,214,1))\n",
        "  detector.compile(optimizer = Adam(0.0002, 0.5),\n",
        "                      loss = \"binary_crossentropy\",\n",
        "                      metrics = [\"accuracy\"])\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    idx = np.random.randint(0, im_array.shape[0], batch_size)\n",
        "    real_imgs = im_array[idx]\n",
        "\n",
        "    idx = np.random.randint(0, im_array_scammers.shape[0], batch_size)\n",
        "    fake_imgs = im_array_scammers[idx]\n",
        "\n",
        "    d_loss_real, d_acc_real = detector.train_on_batch(real_imgs, ones)\n",
        "    d_loss_fake, d_acc_fake = detector.train_on_batch(fake_imgs, zeros)\n",
        "    d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "    d_acc = (d_acc_real + d_acc_fake) / 2\n",
        "\n",
        "    d_losses.append(d_loss)\n",
        "    d_accs.append(d_acc)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"epoch: {epoch+1} / {epochs}, d_loss: {d_loss:.2f}, d_acc: {d_acc:.2f}\")"
      ],
      "metadata": {
        "id": "1tKcg1IREbH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Save the model and weights (Make sure to download them on your hard drive)"
      ],
      "metadata": {
        "id": "N5iIMQWAEyYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector.save(\"detector_model.h5\")\n",
        "detector_weights = detector.get_weights()\n",
        "np.save('detector_weights', detector_weights)"
      ],
      "metadata": {
        "id": "n79eX5wjEzZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Run below if you want the diagram for loss and accuracy of the model over time"
      ],
      "metadata": {
        "id": "yCwapnLOE1yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_losses, label = \"d_losses\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "8jAhzud-E4ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_accs, label = \"d_accs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "87WygDTEE8IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF Lite file for mobile app**"
      ],
      "metadata": {
        "id": "uMIk3E5WFD4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ If you have saved the trained model and haven't done additional training, run below"
      ],
      "metadata": {
        "id": "XpCVZ5dxF1gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector_loaded = tf.keras.load_model(\"detector_model.h5\")\n",
        "detector_weights = np.load(\"detector_weights\", allow_pickle = True)\n",
        "\n",
        "detector_loaded.set_weights(detector_weights)"
      ],
      "metadata": {
        "id": "d21SfYQpF0Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Below convert the model to tflite file which can be used in mobile app development"
      ],
      "metadata": {
        "id": "QrLRCvl0F-0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(detector_loaded) ## change the name according to the current name of the detector\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"detector_model.tflite\", \"wb\") as f:\n",
        "  f.write(tfile_model)"
      ],
      "metadata": {
        "id": "AbZSjLLqFGIx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}